{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install all requried libraries"
      ],
      "metadata": {
        "id": "lZuNZ1OUlDZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch torchvision\n",
        "!pip install -U openai-whisper transformers spacy sentence-transformers\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMu4Na57lJaA",
        "outputId": "35dc356d-ed72-4523-b7e9-206cc56eef05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries and Load models"
      ],
      "metadata": {
        "id": "3AQrEgnmlOTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import spacy\n",
        "from google.colab import files\n",
        "from transformers import pipeline\n",
        "import whisper\n",
        "\n",
        "# Load all models once to avoid reloading them again and again.\n",
        "uploaded = files.upload()\n",
        "audio_file_name = next(iter(uploaded))\n",
        "\n",
        "print(\"Loading all required models...\")\n",
        "try:\n",
        "    # Load Whisper for transcription\n",
        "    whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Load model for classification\n",
        "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "    # Load model for summarization\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "    # Load Spacy for location detection\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    print(\"All models loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading models: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Dm3FPj-glW4G",
        "outputId": "c6213802-14cf-41d9-8edf-97a080d76d26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2745bed1-044f-4b19-b4f5-6d859293643a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2745bed1-044f-4b19-b4f5-6d859293643a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving call_124.mp3 to call_124.mp3\n",
            "Loading all required models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Whisper Model to transcribe the text\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(audio_file_name, task=\"translate\")\n",
        "english_text = result[\"text\"]\n",
        "print(english_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUjVmx5ZsgMm",
        "outputId": "8bda257a-a15f-414e-df1d-33e1f3032d36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Now I won't want to disturb, right, it's me. Yes, I have a gun and I don't, it's from Ali, I've loaded and some of this is a shot. I don't even know what happened. Okay, where are you? Say it one more time. Yes, it's as soon as you can. Is this an apartment or a house? Yes, I have a house. Yes, I have a house. Now I suppose I'll just call a place. Thank you. Please enjoy the music while your party is reached. Okay, this is a novel on upper here. What apartment number are you all in? Where is the person shot? Oh my god, oh my god. Where is the person shot? It's a female. Yes, it's a female. Miss Linda, get me a message for that please. Is someone shot in the chest? Okay, you can't form. Okay, now it's the inside or outside? No, I'm not. Is the inside, okay, listen, is the inside or outside? She's inside, she's inside. Is it a white female, black female? Honey, is it a white female or black female? Yes, it is white. Okay, what is her name? Yes, but it's actually... Okay, what is your name? It's your phone number. I'm on the phone with 911. I don't know what to do. This family is on my own, okay, we have police coming and we have an ambulance coming, okay? Yes, what do we do? Okay, this should be an office or a plenum. Now, okay, I'm going to chance you over to the ambulance. Okay, I think there's someone on my own to the ambulance already. But I'm going to go ahead and send you over there, too, okay? Okay, what is there anything you want to do? Give me an adult. Now, I'm going to ask for the majesty emergency. Okay, what happened? Something, something I was going to go to more often, no idea how it happened with the girl with a shopping cap. Tell me back what happened. Hey, some how we got... How we going off and the girl with a shopping cap? Okay. I'm going to ask you some questions, I've got help to you on the way, okay? Yes. Are you with her now? Yes. How old is she? How old is she? I can't hear the fuck you're saying 20. I mean, I'm doing only 10. How old is she? I don't know, 20. 20. Is she awake? I don't know. Is she conscious? I'm not at all. She's not responding at all. Is she conscious? No. Is she breathing? No. Okay. Are you not conscious or bleeding so that we don't chat? No, I'm not. Okay. Is the attacker still nearby? Nobody attacked her. Nobody attacked her? This is a complete accident. I have no idea. Okay, is there any serious bleeding? Yes. Okay, I'm seeing the paramedics to help you now. Stay on the line. I'll tell you exactly what to do next. Okay. Do not use the turn account. I'm going to tell you how to stop the bleeding, okay? Okay. Okay. Listen carefully to make sure we do it right. Get a clean, dry cloth or towel. I don't know what towels we use. I don't know what towels we use. I don't know. Start. Please enjoy the music while your party is reached. Sir, I need you to stay on the line with me. Do not hang up. I'm trying to help her. I'm sorry, the carmaker. Please help us or just got here. The police officer did? Yes. Okay, I'll let him take over. 911, what is your emergency? I have someone shot. You wet? We have someone shot. Okay, calm down and talk to me. Okay, we have that call. Did you see? Back to the hospital. Back to the hospital. All right, all right. Did you see it? Are you all? No, I don't know what happened. I just heard it. I don't know. Is it gone? We're going to shot. Shot shot. She got shot? Did you see anything? I didn't see anything. I just saw a boy. I just saw a boy. I just saw a boy. I saw a boy. You just saw what? What? D-L-O-O-D-L-D. Okay, well, you need to calm down and talk to me. What else is going on? That's it. I mean, like, it was an accidental discharge. There's no evidence that I was done. I'm a little happy to see this. Is she in the house with you? Yes. Okay, well, we have people coming, okay? So you just calm down. All right, thank you. Okay. Hello? Yeah, I'm just looking. Okay, so everything is still going okay? We have... Can you tell me what happened? Okay, well, hey, sounds like they have a cops coming. Go over here. Hurry up. Who is that talking? It's not good. Just try it. Okay, well, listen. Listen, what's your name? Oh, my God. What's your name? What's your name? What is it? I'm going to need to calm down and talk to me, okay? I'm not. Yeah, I know. I didn't see that. But I mean, like, I'm not going to tell you. I mean, like, what about my stranger? Did you go to your house? Okay, I need you to stand there and tell me what's going on until the officers get there. What happened? I can't tell you what happened. I don't know. I mean, like, I wasn't really there. I guess my friend has gone. You know, like, you were left around with me. And I guess you shot. But you were acting in a shot. I hit it with a loader, I guess. Okay, and you say your friend? Yeah. What's your friend's name? I don't know what to say. Okay, well, you go out to tell the officer. The friend's still there that shot her? Yeah. What's his name? Yeah. I can't, I'm not going to say anything. I'm not going to say anything. Okay, well, why did he shoot her? He didn't lose her. I mean, I wasn't there, but I'm sure he didn't lose her. Okay, you just told me, you gave me a whole bunch of other information. You said that the friend had the gun and he didn't know that it was bullets in there. And he shot the female. Okay, so what did I ask you then, or did he mean to do it? I can't tell you. I was there, but I'm pretty sure that's it. I mean, like, you have girlfriend and everything. What's the female's name? I don't know. I don't know if he's telling you that he's one of girlfriend's friends, but not sure. Is it his girlfriend, you say it? You know what? You know what? The same ambulance right now. Yeah, I can't deal with it. Okay, you said it was stay on the phone with me until the officer did it. I'll get that phone. The same ambulance right now. They have ambulance and police comments. Yeah. Thank you. Bye-bye. Got one more with you, Verdes? Yeah. Someone just got shot in the arm. We're in heritage. Someone got shot in the arm. Yeah. Who shot them? I have no idea. I don't know what happened. Just someone got shot in the arm. What did you get shot in the arm? A-k-7-k. Someone got hit in an A-k-74, someone shot him with. Okay, and they got shot with a rifle? Yeah. Okay. Are you all with? And some girl got shot too. A girl got shot with. And another girl got shot too. So two girls got shot? No, no, a guy and a girl. Okay. A guy and a girl. Where was she shot at? A guy and a girl. What's her name? What's her name? What's her name? Ashley? Where did she get it, Anne? She's okay. I don't know her name. I just ran into it. I just ran to it. I just heard about it. I'm going to get the girl. The guy is sending outside in the front. I'm going to get the girl. Okay. I'm going to run a girl. Okay. I really don't know what happened. Like I was just hanging out. And I just heard someone just got shot. Okay, what's her name? Where's the guy? What's her name? He is standing. Who's in route? For far. Okay, we've got officers in the area. And he is standing outside of the house. The officer is? No, no, I'm saying the guy is. Is that your shot? The guy who shot him? No, the guy who's got shot is thinking outside the house. Okay. All right, we have police officers that are there. They're going to make contact with you guys. Okay. I don't know. I'm going to sort of throw a gun at you on the face. I don't know if that's true or not. Okay. So, you know where she's at? I was in here. I just ran out of stairs and look. But I haven't seen it. I'm there. I really don't know. Okay. Is it you? Yeah. Yeah, I'm sorry, I guess. Okay, the girl. The girl? Is there a girl? Yeah, I'm sorry. Contact with everyone. We had the cops are here. Okay. All right, bye. Bye. Now, I want one. What is your emergency? I can't hear you, son. I can't hear you, son again. I'm not going to be all back. I'm going to be a police officer. Okay, I can't hear you, ma'am. What's going on? I'm going to be a police officer. I can't hear you, ma'am. What's going on? I'm going to be a police officer. I'm not going to chase you. I'm not going to chase you. I'm not going to be a police officer. I'm not catching up. I am. Where are you on the promised slide? I may not be able to believe you. I'm not going to burn your butt. burial lap. I'm going not to push you. I'm not going to beat you. I'm not going to shoot you, or you should get arguing. And she's because of me. You are our religion. How is the good morning. Do you need to know what's happening? I want to go girlfriend of dead men. Why don't you talk with her? It's my bad evening, 제대로. If something is so horrible that you don't lose it's right out. What's wrong, mom? I need some more. Man. Hello. Yes, I need some more. What's the address? I need some more. Man. I need some more. I need some more. Yes. Yes. Your call has been forwarded to an automatic voice message system. Not.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorize the complaint into predefined crime categories\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "categories = ['Robbery', 'Assault', 'Cybercrime', 'Theft', 'Domestic Violence', 'Fraud', 'Missing Person', 'Harassment']\n",
        "result = classifier(english_text, categories)\n",
        "print(\"Category:\", result[\"labels\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKP3n3rvss_r",
        "outputId": "a0e8d063-5cdf-40b4-d792-c137aecbb6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category: Domestic Violence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usecase 1 : Analyze the transcribed text to determine the level of danger or threat present in the person's speech.\n",
        "\n",
        "high_threat = [\"kill\", \"gun\", \"shoot\", \"bomb\", \"murder\", \"attack\", \"knife\", \"rape\"]\n",
        "medium_threat = [\"beat\", \"threat\", \"follow\", \"scared\", \"stab\", \"danger\"]\n",
        "low_threat = [\"scold\", \"argument\", \"push\", \"fight\", \"harass\"]\n",
        "\n",
        "def get_danger_score(text):\n",
        "    text = text.lower()\n",
        "    score = 1\n",
        "    for word in high_threat:\n",
        "        if re.search(r'\\b' + re.escape(word) + r'\\b', text):\n",
        "            score += 2\n",
        "    for word in medium_threat:\n",
        "        if re.search(r'\\b' + re.escape(word) + r'\\b', text):\n",
        "            score += 1\n",
        "    for word in low_threat:\n",
        "        if re.search(r'\\b' + re.escape(word) + r'\\b', text):\n",
        "            score += 0.5\n",
        "    return min(5, round(score))\n",
        "\n",
        "score = get_danger_score(english_text)\n",
        "print(\"Danger Score:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg-e0GQ4tznj",
        "outputId": "f6160588-8f38-412c-c573-b5159a8779df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danger Score: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usecase 2 : Concise summary of the person's statement to quickly understand the context of the conversation.\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "summary = summarizer(english_text, max_length=100, min_length=20, do_sample=False)\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DsK1IH9udqA",
        "outputId": "79805429-1608-4f22-dea8-89be26462e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Santa's the emergency\" asks caller if he has a gun or a knife. \"I want to get a really good description of this guy so we catch him\" \"He's wearing a giant sweater and a shark hat. A giant sweatshirt and an... What is it? Giant sweater and giant hat\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usecase 3 : Extract the location mentioned by the person to identify where the incident\n",
        "import numpy as np\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "fake_locations = {'Santa', 'Today', 'Tomorrow', 'Someone', 'Anything', 'Nobody'}\n",
        "\n",
        "def extract_locations(text):\n",
        "    doc = nlp(text)\n",
        "    locations = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"GPE\", \"LOC\", \"FAC\"]:\n",
        "            loc = ent.text.strip()\n",
        "            if len(loc) > 3 and loc not in fake_locations and loc[0].isupper():\n",
        "                locations.append(loc)\n",
        "    return list(set(locations)) if locations else [np.nan]\n",
        "\n",
        "locations = extract_locations(english_text)\n",
        "print(\"Locations:\", locations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrMyt_f1uvmN",
        "outputId": "0a161aa0-8440-4d2f-a097-40e19cf77f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Locations: [nan]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}